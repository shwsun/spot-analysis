{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Spot resources Analytics\n",
    "\n",
    "Here we perform some initial process and analysis on the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With static dataset, e.g. load the grabbed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# parse the data file and extra the results\n",
    "filename = 'data1'\n",
    "\n",
    "df = pd.read_csv(filename, sep=\"\\t\", header = None)\n",
    "df.columns = [\"info\", \"SpotPrice\", \"TimeStamp\", \"InstanceType\", \"OS type\", \"AvailabilityZone\"]\n",
    "df['TimeStamp'] =pd.to_datetime(df.TimeStamp)\n",
    "\n",
    "df.index = df.TimeStamp\n",
    "df = df.drop('info', 1).drop(['OS type'],axis=1)\n",
    "df = df.drop(['TimeStamp'],axis=1).sort_index()\n",
    " \n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (df['InstanceType'].unique())\n",
    "print (df['AvailabilityZone'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instance_types  = ['c3.xlarge', 'c3.2xlarge', 'c3.4xlarge', 'c3.8xlarge']\n",
    "region = 'us-east-1'\n",
    "\n",
    "df1 = df[df.AvailabilityZone == 'us-west-1a']\n",
    "df2 = df1[df1.InstanceType == 'c3.8xlarge']\n",
    "df2.to_csv('us-east-1a_c3-8xlarge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, g in df1.sort_index(ascending=True).groupby(['InstanceType'], as_index=False):\n",
    "    for key, grp in g.groupby(['AvailabilityZone'], as_index=False):\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(grp.index, grp['SpotPrice'], label=key)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.title('Spot Pricing - ' + k)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, g in df1.sort_index(ascending=True).groupby(['InstanceType'], as_index=False):\n",
    "    #plt.figure(1, figsize(20,5))\n",
    "    for key, grp in g.groupby(['AvailabilityZone'], as_index=False):\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.hist(grp['SpotPrice'], bins=100, label=key,)\n",
    "        plt.xlim([0, 1])\n",
    "        #grp.groupby(grp.index.dayofweek).agg(['mean']).plot()\n",
    "    plt.legend()\n",
    "    plt.title('Histogram of Spot Pricing - ' + k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we grad dataset from AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instance_types  = ['c3.xlarge', 'c3.2xlarge', 'c3.4xlarge', 'c3.8xlarge']\n",
    "region = 'us-east-1'\n",
    "number_of_days = 10\n",
    "\n",
    "end = !date -u \"+%Y-%m-%dT%H:%M:%S\"\n",
    "end = end[0]\n",
    "start = !date -v-{number_of_days}d -u \"+%Y-%m-%dT%H:%M:%S\"\n",
    "\n",
    "#start = !date -v-{number_of_days}d\" -u \"+%Y-%m-%dT%H:%M:%S\"\n",
    "#print(start)\n",
    "start = start[0]\n",
    "print (\"will process from \" + start + \" to \" + end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto as boto\n",
    "import boto.ec2 as ec2\n",
    "import datetime, time\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.mpl_style', 'default')  # Make the graphs a bit prettier\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "ec2 = boto.ec2.connect_to_region(region)\n",
    "\n",
    "\n",
    "#\n",
    "# process the output and convert to a dataframe\n",
    "#\n",
    "\n",
    "l = []\n",
    "for instance in instance_types:\n",
    "    sys.stdout.write(\"*** processing \" + instance + \" ***\\n\")\n",
    "    sys.stdout.flush()\n",
    "    prices = ec2.get_spot_price_history(start_time=start, end_time=end, instance_type=instance)\n",
    "    for price in prices:\n",
    "        d = {'InstanceType': price.instance_type, \n",
    "             'AvailabilityZone': price.availability_zone, \n",
    "             'SpotPrice': price.price, \n",
    "             'Timestamp': price.timestamp}\n",
    "        l.append(d)\n",
    "    next = prices.next_token\n",
    "    while (next != ''):\n",
    "        sys.stdout.write(\".\")\n",
    "        sys.stdout.flush()\n",
    "        prices = ec2.get_spot_price_history(start_time=start, end_time=end, instance_type=instance,\n",
    "                                            next_token=next )\n",
    "        for price in prices:\n",
    "            d = {'InstanceType': price.instance_type, \n",
    "                 'AvailabilityZone': price.availability_zone, \n",
    "                 'SpotPrice': price.price, \n",
    "                 'Timestamp': price.timestamp}\n",
    "            l.append(d)\n",
    "        next = prices.next_token\n",
    "        \n",
    "    sys.stdout.write(\"\\n\")\n",
    "\n",
    "df = pd.DataFrame(l)\n",
    "df = df.set_index(pd.to_datetime(df['Timestamp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis #1\n",
    "**Problems:** Can we predict future price of a spot instance given previous history and how other vm’s are reacting?\n",
    "\n",
    "To achieve the goal of prediction, we are expecting to do pattern matching from the collected dataset. In this case, whenever users make a bid, we can based on the resources types, time or day, and the trending price to do pattern matching. We will be able to provide a prediction if we can shoot a pattern.\n",
    "\n",
    "Expecting tools are supervised and unsupervised learning algorithms, e.g. classification and\n",
    "clustering methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis #2\n",
    "\n",
    "For each machine type there exists a region that is more favorable to use, as the market volatility is very low and the prices tend to stay cheaper than the other regions.\n",
    "\n",
    "With in proving this hypothesis users will be able to find the best region they should be bidding in, as long as latency is not an issue for them.\n",
    "\n",
    "Data Science tools & Techniques: We can use clustering and classification methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-17 08:01:54\n",
      "2015-03-19 07:42:11\n",
      "60 days 23:40:17\n"
     ]
    }
   ],
   "source": [
    "print (df.index.min())\n",
    "print (df.index.max())\n",
    "print(df.index.max()- df.index.min()) \n",
    "#df = df.truncate(before='2015-01-16', after='2015-3-18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.resample('H')\n",
    "df = df.fillna(\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create full time series and fill data\n",
    "dfSorted = df.groupby(['AvailabilityZone', 'InstanceType'])\n",
    "dfSorted = dfSorted.resample('H')\n",
    "dfSorted = dfSorted.fillna(\"ffill\")\n",
    "\n",
    "dfSorted=dfSorted.drop('InstanceType', axis=1).drop('AvailabilityZone', axis=1)\n",
    "\n",
    "dfSorted.to_csv(\"im.csv\")\n",
    "depa = pd.read_csv(\"im.csv\")\n",
    "depa = depa.groupby(['AvailabilityZone', 'InstanceType'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor name, group in depa:\\n    if name[0] ==\"ap-northeast-1a\":\\n        #group.index = group[\\'TimeStamp\\']\\n        #print(group.head(20))\\n        #group = group.truncate(before=\\'2015-01-18\\', after=\\'2015-3-17\\')\\n        d[name[1]]=group[\\'SpotPrice\\'].tolist()\\n        print(len(group[\\'SpotPrice\\'].tolist()))\\n'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouped_prices = [group['SpotPrice'].tolist() for name, group in depa]\n",
    "\n",
    "#dfer = dataframe\n",
    "d = {}\n",
    "\n",
    "count = 0\n",
    "#need to run through and get rid of rows where timestamp, spotprice data doesnt exist for the others\n",
    "for name, group in depa:\n",
    "    if count == 0:\n",
    "        d['TimeStamp']=group['TimeStamp'].tolist()\n",
    "    if name[0] ==\"ap-northeast-1a\":\n",
    "        for a in d['TimeStamp']+group['TimeStamp'].tolist():\n",
    "            if(a not in d['TimeStamp']):\n",
    "                group = group[group['TimeStamp'] != a]\n",
    "                print (a)\n",
    "            if(a not in group['TimeStamp'].tolist()):\n",
    "                d['TimeStamp'].remove(a)\n",
    "                print (a)\n",
    "    \n",
    "    \n",
    "    #seter = set(d['TimeStamp']) - set(group['TimeStamp'].tolist())\n",
    "    #print(seter)\n",
    "    #remove = list(seter)\n",
    "    #print(remove)    \n",
    "#dfer = pd.DataFrame(d)\n",
    "    \n",
    "#for name, group in depa:\n",
    "     #print(len(group['SpotPrice'].tolist()))\n",
    "        \n",
    "'''\n",
    "for name, group in depa:\n",
    "    if name[0] ==\"ap-northeast-1a\":\n",
    "        #group.index = group['TimeStamp']\n",
    "        #print(group.head(20))\n",
    "        #group = group.truncate(before='2015-01-18', after='2015-3-17')\n",
    "        d[name[1]]=group['SpotPrice'].tolist()\n",
    "        print(len(group['SpotPrice'].tolist()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#numpy.corrcoef(grouped_prices)\n",
    "\n",
    "grouped_prices.corr()\n",
    "'''\n",
    "mask = np.zeros_like(corr_df)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "seaborn.heatmap(corr_df, cmap='RdYlGn_r', vmax=1.0, vmin=-1.0 , mask = mask, linewidths=2.5)\n",
    "# Show the plot we reorient the labels for each column and row to make them easier to read.\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=90) \n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Hypothesis #3\n",
    "\n",
    "There exists some kind of relation between what kind of virtual machines are turning into hotspots. Say that we establish a line as half price of EC2 instances, it makes sense to pay half price to gain usage of resources but probably not more than 3⁄4. By extracting patterns from the price history, we can study that whether or not there was the case that some resources were becoming hotspot in the spot instances market.\n",
    "\n",
    "Potential data science method for this one includes: Time Series, Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('us-east-1a_c3-8xlarge.csv')\n",
    "#df.head(400)\n",
    "df = df2\n",
    "df.describe()\n",
    "\n",
    "df.SpotPrice.plot(label='Spot Price of c3.8xlarge', figsize = (15,5))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset pre-process\n",
    "\n",
    "Some preprocess work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpotPrice</th>\n",
       "      <th>InstanceType</th>\n",
       "      <th>OS type</th>\n",
       "      <th>AvailabilityZone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeStamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-02-16 00:54:00</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>m1.small</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>us-west-1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 00:55:30</th>\n",
       "      <td>2.7320</td>\n",
       "      <td>c3.8xlarge</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>us-west-1a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 00:58:09</th>\n",
       "      <td>0.0679</td>\n",
       "      <td>m3.large</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>us-west-1b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 00:59:56</th>\n",
       "      <td>3.0240</td>\n",
       "      <td>c3.8xlarge</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:17:30</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>m3.medium</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>us-east-1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:17:37</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>m1.small</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>us-west-1b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:24:19</th>\n",
       "      <td>0.7561</td>\n",
       "      <td>c3.2xlarge</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:24:19</th>\n",
       "      <td>0.7561</td>\n",
       "      <td>c3.2xlarge</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:24:25</th>\n",
       "      <td>0.0926</td>\n",
       "      <td>m3.xlarge</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:24:26</th>\n",
       "      <td>3.0241</td>\n",
       "      <td>c3.8xlarge</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:24:26</th>\n",
       "      <td>0.1891</td>\n",
       "      <td>c3.large</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:24:26</th>\n",
       "      <td>0.1891</td>\n",
       "      <td>c3.large</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:24:27</th>\n",
       "      <td>0.3781</td>\n",
       "      <td>c3.xlarge</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:24:28</th>\n",
       "      <td>1.5121</td>\n",
       "      <td>c3.4xlarge</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-02-16 01:24:28</th>\n",
       "      <td>1.5121</td>\n",
       "      <td>c3.4xlarge</td>\n",
       "      <td>Linux/UNIX</td>\n",
       "      <td>ap-southeast-2a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SpotPrice InstanceType     OS type AvailabilityZone\n",
       "TimeStamp                                                               \n",
       "2014-02-16 00:54:00     0.0100     m1.small  Linux/UNIX       us-west-1a\n",
       "2014-02-16 00:55:30     2.7320   c3.8xlarge  Linux/UNIX       us-west-1a\n",
       "2014-02-16 00:58:09     0.0679     m3.large  Linux/UNIX       us-west-1b\n",
       "2014-02-16 00:59:56     3.0240   c3.8xlarge  Linux/UNIX  ap-southeast-2a\n",
       "2014-02-16 01:17:30     0.0224    m3.medium  Linux/UNIX       us-east-1d\n",
       "2014-02-16 01:17:37     0.0100     m1.small  Linux/UNIX       us-west-1b\n",
       "2014-02-16 01:24:19     0.7561   c3.2xlarge  Linux/UNIX  ap-southeast-2b\n",
       "2014-02-16 01:24:19     0.7561   c3.2xlarge  Linux/UNIX  ap-southeast-2a\n",
       "2014-02-16 01:24:25     0.0926    m3.xlarge  Linux/UNIX  ap-southeast-2b\n",
       "2014-02-16 01:24:26     3.0241   c3.8xlarge  Linux/UNIX  ap-southeast-2b\n",
       "2014-02-16 01:24:26     0.1891     c3.large  Linux/UNIX  ap-southeast-2b\n",
       "2014-02-16 01:24:26     0.1891     c3.large  Linux/UNIX  ap-southeast-2a\n",
       "2014-02-16 01:24:27     0.3781    c3.xlarge  Linux/UNIX  ap-southeast-2a\n",
       "2014-02-16 01:24:28     1.5121   c3.4xlarge  Linux/UNIX  ap-southeast-2b\n",
       "2014-02-16 01:24:28     1.5121   c3.4xlarge  Linux/UNIX  ap-southeast-2a"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# parse the data file and extra the results\n",
    "filename = 'aws-spot-price-history/data-1397804701'\n",
    "\n",
    "df = pd.read_csv(filename, sep=\"\\t\", header = None)\n",
    "df.columns = [\"info\", \"SpotPrice\", \"TimeStamp\", \"InstanceType\", \"OS type\", \"AvailabilityZone\"]\n",
    "df['TimeStamp'] =pd.to_datetime(df.TimeStamp)\n",
    "\n",
    "df.index = df.TimeStamp\n",
    "df = df.drop(['TimeStamp'],axis=1).drop('info', 1).sort_index()\n",
    "\n",
    "\n",
    "df.head(15)\n",
    "#df['SpotPrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c3.xlarge\n",
      "c3.2xlarge\n",
      "c3.4xlarge\n",
      "c3.8xlarge\n"
     ]
    }
   ],
   "source": [
    "instance_types  = ['c3.xlarge', 'c3.2xlarge', 'c3.4xlarge', 'c3.8xlarge']\n",
    "region1 = 'us-east-1'\n",
    "\n",
    "df1 = df[df.AvailabilityZone == 'us-west-1a']\n",
    "df2 = df1[df1.InstanceType == 'c3.8xlarge']\n",
    "df2.to_csv('us-east-1a_c3-8xlarge.csv')\n",
    "\n",
    "df2 = df1[df1.InstanceType == 'c3.4xlarge']\n",
    "df2.to_csv('us-east-1a_c3-4xlarge.csv')\n",
    "\n",
    "df2 = df1[df1.InstanceType == 'c3.2xlarge']\n",
    "df2.to_csv('us-east-1a_c3-2xlarge.csv')\n",
    "\n",
    "df2 = df1[df1.InstanceType == 'c3.xlarge']\n",
    "df2.to_csv('us-east-1a_c3-xlarge.csv')\n",
    "\n",
    "for i in instance_types:\n",
    "    print(i)\n",
    "    df1 = df[df.AvailabilityZone == region1]\n",
    "    df2 = df1[df1.InstanceType == i]\n",
    "    #df2.to_csv(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor k, g in df1.sort_index(ascending=True).groupby(['InstanceType'], as_index=False):\\n    for key, grp in g.groupby(['AvailabilityZone'], as_index=False):\\n        plt.figure(figsize=(15,5))\\n        plt.plot(grp.index, grp['SpotPrice'], label=key)\\n        \\n    plt.legend()\\n    plt.title('Spot Pricing - ' + k)\\n    plt.show()\\n\\nfor k, g in df1.sort_index(ascending=True).groupby(['InstanceType'], as_index=False):\\n    #plt.figure(1, figsize(20,5))\\n    for key, grp in g.groupby(['AvailabilityZone'], as_index=False):\\n        plt.figure(figsize=(15,5))\\n        plt.hist(grp['SpotPrice'], bins=100, label=key,)\\n        plt.xlim([0, 1])\\n        #grp.groupby(grp.index.dayofweek).agg(['mean']).plot()\\n    plt.legend()\\n    plt.title('Histogram of Spot Pricing - ' + k)\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for k, g in df1.sort_index(ascending=True).groupby(['InstanceType'], as_index=False):\n",
    "    for key, grp in g.groupby(['AvailabilityZone'], as_index=False):\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(grp.index, grp['SpotPrice'], label=key)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.title('Spot Pricing - ' + k)\n",
    "    plt.show()\n",
    "\n",
    "for k, g in df1.sort_index(ascending=True).groupby(['InstanceType'], as_index=False):\n",
    "    #plt.figure(1, figsize(20,5))\n",
    "    for key, grp in g.groupby(['AvailabilityZone'], as_index=False):\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.hist(grp['SpotPrice'], bins=100, label=key,)\n",
    "        plt.xlim([0, 1])\n",
    "        #grp.groupby(grp.index.dayofweek).agg(['mean']).plot()\n",
    "    plt.legend()\n",
    "    plt.title('Histogram of Spot Pricing - ' + k)\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Clustering\n",
    "\n",
    "## Time series clustering on spot market price data set.\n",
    "\n",
    "Here we will be using TSC to analyse relations between various of types of machines and find out relationships from our clustering results.\n",
    "\n",
    "The first step is to work out an appropriate distance/similarity metric. Secondly, we will use existing clustering techniques, such as k-means, hierarchical clustering, density-based clustering or subspace clustering, to find clustering structures.\n",
    "\n",
    "Dynamic Time Warping (DTW) finds optimal alignment between two time series, and DTW distance is used as a distance metric in the example below.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A data set of Synthetic Control Chart Time Series is used here, which contains 600 examples of control charts. Each control chart is a time series with 60 values. There are six classes: 1) 1-100 Normal, 2) 101-200 Cyclic, 3) 201-300 Increasing trend, 4)301-400 Decreasing trend, 5) 401-500 Upward shift, and 6) 501-600 Downward shift. The dataset is downloadable at UCI KDD Archive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "1. [Mining Time-series with Trillions of Points: Dynamic Time Warping at scale](http://practicalquant.blogspot.com/2012/10/mining-time-series-with-trillions-of.html)\n",
    "2. [sackoverflow post](http://stackoverflow.com/questions/34940808/hierarchical-clustering-of-time-series-in-python-scipy-numpy-pandas)\n",
    "3. [scilearn material](http://scikit-learn.org/stable/modules/clustering.html)\n",
    "4. [pattern matching over time series data](http://stats.stackexchange.com/questions/136091/sequential-pattern-matching-in-time-series-data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
